{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bfgs_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuhiG/MNIST-in-Tensorflow/blob/master/bfgs_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "a1PmLEUhrVWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "6393f1ee-c12c-4efb-c14a-adbd8bb7b352"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "\n",
        "# Import MNIST data\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "# mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
        "mnist=read_data_sets(\"data\",one_hot=True)\n",
        "\n",
        "# Set parameters\n",
        "learning_rate = 0.01\n",
        "training_iteration = 30\n",
        "batch_size = 100\n",
        "display_step = 2\n",
        "\n",
        "# TF graph input\n",
        "x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
        "y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes\n",
        "\n",
        "\n",
        "# Create a model\n",
        "\n",
        "# Set model weights\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "with tf.name_scope(\"Wx_b\") as scope:\n",
        "    # Construct a linear model\n",
        "    model = tf.nn.sigmoid(tf.matmul(x, W) + b) # Softmax\n",
        "    \n",
        "# Add summary ops to collect data\n",
        "# w_h = tf.summary.histogram(\"weights\", W)\n",
        "# b_h = tf.summary.histogram(\"biases\", b)\n",
        "\n",
        "# More name scopes will clean up graph representation\n",
        "with tf.name_scope(\"cost_function\") as scope:\n",
        "    # Minimize error using cross entropy\n",
        "    # Cross entropy\n",
        "    cost_function = tf.losses.mean_squared_error(y,model)\n",
        "    # Create a summary to monitor the cost function\n",
        "#     tf.summary.scalar(\"cost_function\", cost_function)\n",
        "\n",
        "with tf.name_scope(\"train\") as scope:\n",
        "    # Gradient descent\n",
        "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
        "    optimizer=tf.contrib.opt.ScipyOptimizerInterface(cost_function,method=\"BFGS\")\n",
        "#      train=optimizer.minimize(cost_function)\n",
        "\n",
        "# Initializing the variables\n",
        "# init = tf.initialize_all_variables()\n",
        "    \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Merge all summaries into a single operator\n",
        "# merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    \n",
        "#     # Change this to a location on your computer\n",
        "#     summary_writer = tf.summary.FileWriter('data/logs', graph_def=sess.graph_def)\n",
        "\n",
        "    # Training cycle\n",
        "    for iteration in range(training_iteration):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            # Fit training using batch data\n",
        "#             sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
        "            optimizer.minimize(sess,feed_dict={x: batch_xs, y: batch_ys})\n",
        "\n",
        "#             sess.run(optimizer,feed_dict={x: batch_xs, y: batch_ys})\n",
        "#             sess.run(train,feed_dict={optimizer})\n",
        "            # Compute the average loss\n",
        "            avg_cost += sess.run(cost_function, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
        "            # Write logs for each iteration\n",
        "#             summary_str = sess.run(merged_summary_op, feed_dict={x: batch_xs, y: batch_ys})\n",
        "#             summary_writer.add_summary(summary_str, iteration*total_batch + i)\n",
        "        # Display logs per iteration step\n",
        "  \n",
        "  \n",
        "#         if iteration % display_step == 0:\n",
        "        print(\"Iteration:\", '%04d' % (iteration + 1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "    print(\"Tuning completed!\")\n",
        "\n",
        "    # Test the model\n",
        "    predictions = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(predictions, \"float\"))\n",
        "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-0f143fd1e9c8>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}